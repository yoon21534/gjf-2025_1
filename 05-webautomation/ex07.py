# ë„¤ì´ë²„ ë‰´ìŠ¤ IT/ê³¼í•™ ì„¹ì…˜ ê°„ë‹¨ í¬ë¡¤ë§

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
import time
import csv
from datetime import datetime

def crawl_naver_it_news():
    """ë„¤ì´ë²„ IT/ê³¼í•™ ë‰´ìŠ¤ í¬ë¡¤ë§"""
    
    # Chrome ì„¤ì •
    options = Options()
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    
    driver = webdriver.Chrome(options=options)
    
    try:
        print("ğŸš€ ë„¤ì´ë²„ IT/ê³¼í•™ ë‰´ìŠ¤ í¬ë¡¤ë§ ì‹œì‘...")
        
        # 1. ë„¤ì´ë²„ ë‰´ìŠ¤ ë©”ì¸ í˜ì´ì§€ ì ‘ì†
        print("ğŸ“° ë„¤ì´ë²„ ë‰´ìŠ¤ ë©”ì¸ í˜ì´ì§€ ì ‘ì† ì¤‘...")
        driver.get("https://news.naver.com/")
        time.sleep(3)
        
        # 2. IT/ê³¼í•™ ë²„íŠ¼ í´ë¦­
        print("ğŸ’» IT/ê³¼í•™ ì„¹ì…˜ìœ¼ë¡œ ì´ë™ ì¤‘...")
        
        # ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ IT/ê³¼í•™ ë²„íŠ¼ ì°¾ê¸°
        selectors = [
            "//a[contains(text(), 'IT/ê³¼í•™')]",
            "//a[@href='/section/105']",
            "//*[contains(@class, 'nav')]//a[contains(text(), 'IT/ê³¼í•™')]",
            "//nav//a[contains(text(), 'IT/ê³¼í•™')]"
        ]
        
        button_clicked = False
        for selector in selectors:
            try:
                it_button = driver.find_element(By.XPATH, selector)
                it_button.click()
                print("âœ… IT/ê³¼í•™ ë²„íŠ¼ í´ë¦­ ì™„ë£Œ")
                time.sleep(3)
                button_clicked = True
                break
            except:
                continue
        
        if not button_clicked:
            # ëª¨ë“  ë°©ë²• ì‹¤íŒ¨ì‹œ ì§ì ‘ URL ì´ë™
            print("âš ï¸ ë²„íŠ¼ í´ë¦­ ì‹¤íŒ¨, ì§ì ‘ URLë¡œ ì´ë™")
            driver.get("https://news.naver.com/section/105")
            time.sleep(3)
        
        # ë‰´ìŠ¤ ë§í¬ ìˆ˜ì§‘
        news_list = []
        links = driver.find_elements(By.XPATH, "//a[contains(@href, '/article/')]")
        
        for i, link in enumerate(links[:10]):  # ìƒìœ„ 10ê°œë§Œ
            try:
                title = link.text.strip()
                url = link.get_attribute('href')
                
                if title and url and len(title) > 10:  # ìœ íš¨í•œ ì œëª©ë§Œ
                    news_list.append({
                        'index': len(news_list) + 1,
                        'title': title,
                        'link': url,
                        'time': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    })
                    print(f"ğŸ“° [{len(news_list)}] {title[:50]}...")
            except:
                continue
        
        return news_list
        
    except Exception as e:
        print(f"âŒ ì—ëŸ¬: {e}")
        return []
    finally:
        driver.quit()

def save_csv(news_list):
    """CSV íŒŒì¼ ì €ì¥"""
    if not news_list:
        print("âŒ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    filename = f"it_news_{datetime.now().strftime('%Y%m%d_%H%M')}.csv"
    
    with open(filename, 'w', newline='', encoding='utf-8-sig') as f:
        writer = csv.DictWriter(f, fieldnames=['index', 'title', 'link', 'time'])
        writer.writeheader()
        writer.writerows(news_list)
    
    print(f"âœ… ì €ì¥ì™„ë£Œ: {filename} ({len(news_list)}ê°œ)")

def main():
    # í¬ë¡¤ë§ ì‹¤í–‰
    news = crawl_naver_it_news()
    
    # ê²°ê³¼ ì¶œë ¥
    if news:
        print(f"\nğŸ“Š ì´ {len(news)}ê°œ ë‰´ìŠ¤ ìˆ˜ì§‘ì™„ë£Œ!")
        save_csv(news)
    else:
        print("âŒ ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()